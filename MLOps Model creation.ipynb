{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning model for integration with Devops (MLOps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation and training using MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\mangl\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\mangl\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\mangl\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\mangl\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\mangl\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\mangl\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\mangl\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\mangl\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\mangl\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\mangl\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\mangl\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\mangl\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test)  = mnist.load_data()  # loads the MNIST dataset\n",
    "\n",
    "# Store the number of rows and columns\n",
    "img_rows = x_train[0].shape[0]\n",
    "img_cols = x_train[1].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Get right 'shape' needed for Keras we add a 4th dimension to the model by changing our original image shape of (60000,28,28) to (60000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (img_rows, img_cols, 1)   # store the shape of a single image \n",
    "\n",
    "# change our image type to float32 data type\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize our data by changing the range from (0 to 255) to (0 to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we one hot encode outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "num_pixels = x_train.shape[1] * x_train.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Layers to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mangl\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2592)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                25930     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 26,250\n",
      "Trainable params: 26,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# first set of CRP (Convolution, RELU, Pooling)\n",
    "\n",
    "def input_layers(conv,nfilter1,filter_size1,pool_size1,fc_input,no_neurons):\n",
    "    #conv = int(input('conv layers :'))\n",
    "    #nfilter1 = int(input('filter layer :'))\n",
    "    #filter_size1 = int(input('filter size :'))\n",
    "    #pool_size1 = int(input('pool layer :'))\n",
    "    this_layer = 'No. of convolve layers : ' + str(conv)\n",
    "    this_layer = this_layer + '\\nLayer 1'\n",
    "    this_layer = this_layer + '\\nNo of filters : ' + str(nfilter1) + '\\nFilter Size : ' + str(filter_size1) + '\\nPool Size : ' + str(pool_size1)\n",
    "\n",
    "    model.add(Conv2D(nfilter1, (filter_size1,filter_size1),padding = \"same\",input_shape = input_shape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size = (pool_size1,pool_size1)))\n",
    "\n",
    "    #Subsequent CRP sets\n",
    "    for i in range(1,conv):\n",
    "        nfilters = int(input('filters layers :'))\n",
    "        filter_size = int(input('filters size :'))\n",
    "        pool_size = int(input('pool size :'))\n",
    "        this_layer = this_layer + '\\nLayer ' + str(i+1) + ': '\n",
    "        this_layer = this_layer + '\\nNo of filters : ' + str(nfilters) + '\\nFilter Size : ' + str(filter_size) + '\\nPool Size : ' + str(pool_size)\n",
    "        model.add(Conv2D(nfilters, (filter_size, filter_size),padding = \"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size = (pool_size, pool_size)))\n",
    "\n",
    "    model.add(Flatten())  # Fully connected layers (w/ RELU)\n",
    "\n",
    "    #fc_input = int(input('FC layer :'))\n",
    "\n",
    "    this_layer = this_layer + '\\nNo. of FC Layers : ' + str(fc_input+1) \n",
    "\n",
    "    for i in range(0,fc_input):\n",
    "        #no_neurons = int(input('neurons :'))\n",
    "        this_layer = this_layer + '\\nNeurons in Layer ' + str(i+1) + ' : ' + str(no_neurons)\n",
    "        model.add(Dense(no_neurons))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "    # Softmax (for classification)\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    this_layer = this_layer + '\\nNeurons in Layer ' + str(fc_input + 1) + ' : ' + str(num_classes)\n",
    "    model.compile(loss = 'categorical_crossentropy',optimizer = keras.optimizers.Adadelta(),metrics = ['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "\n",
    "input_layers(1,32,3,3,0,16)    # Adding layers to layers function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let us train LeNet on our MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mangl\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 23s 381us/step - loss: 0.3636 - accuracy: 0.8970 - val_loss: 0.1510 - val_accuracy: 0.9576\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 22s 361us/step - loss: 0.1318 - accuracy: 0.9622 - val_loss: 0.0986 - val_accuracy: 0.9710\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 23s 380us/step - loss: 0.0970 - accuracy: 0.9718 - val_loss: 0.0808 - val_accuracy: 0.9758\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 22s 362us/step - loss: 0.0816 - accuracy: 0.9762 - val_loss: 0.0716 - val_accuracy: 0.9777\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 23s 386us/step - loss: 0.0726 - accuracy: 0.9782 - val_loss: 0.0685 - val_accuracy: 0.9792\n",
      "10000/10000 [==============================] - 2s 208us/step\n",
      "Test loss: 0.0685330237729475\n",
      "Test accuracy: 0.979200005531311\n"
     ]
    }
   ],
   "source": [
    "def training():\n",
    "    batch_size = 128\n",
    "    epochs = 5\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "    model.save(\"mlops.h5\")\n",
    "\n",
    "    # Evaluate the performance of our trained model\n",
    "    global scores\n",
    "    scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "    print('Test loss:', scores[0])\n",
    "    print('Test accuracy:', scores[1])\n",
    "    \n",
    "training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retraining the model by checking accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scores[1] < 0.95 :\n",
    "    input_layers(2,64,3,3,1,32)\n",
    "    training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Save accuracy to particular file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_file = open('/MLops/accuracy.txt','w') \n",
    "accuracy_file.write(str(scores[1]))\n",
    "accuracy_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
